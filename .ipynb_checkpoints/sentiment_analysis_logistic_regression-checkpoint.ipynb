{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all imports are here\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /home/muzammil/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/muzammil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples,stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer(preserve_case=False,strip_handles=True,reduce_len=True)\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweets(tweet):\n",
    "    #removing old style retweet text RT\n",
    "    tweet = re.sub(r'RT[\\s]+','',tweet)\n",
    "    #removing hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    tweet_tokens = tokenizer.tokenize(tweet) #tokenizing tweets\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if word in stopwords.words('english') or word in string.punctuation:\n",
    "            continue\n",
    "        else:\n",
    "            tweets_clean.append(word)\n",
    "    tweets_stem = []\n",
    "    for word in tweets_clean:\n",
    "        stem_word  = stemmer.stem(word)\n",
    "        tweets_stem.append(stem_word)\n",
    "    return tweets_stem\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_frequency_dictionary(X,Y):\n",
    "    frequency_dictionary = {}\n",
    "    for label,tweet in zip(Y,X):\n",
    "        for word in tweet:\n",
    "            if (word,label) in frequency_dictionary:\n",
    "                frequency_dictionary[(word,label)]+=1\n",
    "            else:\n",
    "                frequency_dictionary[(word,label)]=1\n",
    "    return frequency_dictionary\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(X,Y,frequency_dictionary):\n",
    "    first_column = np.ones(len(X))\n",
    "    second_column = []\n",
    "    third_column = []\n",
    "    positive_label = Y[0]\n",
    "    negative_label = Y[len(Y)-1]\n",
    "    for tweet in X:\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        \n",
    "        for word in tweet:\n",
    "            if (word,positive_label) in frequency_dictionary:\n",
    "                pos+=frequency_dictionary[(word,positive_label)]\n",
    "            if (word,negative_label) in frequency_dictionary:\n",
    "                neg+=frequency_dictionary[(word,negative_label)]\n",
    "        second_column.append(pos)\n",
    "        third_column.append(neg)\n",
    "    return np.column_stack((first_column,second_column,third_column))    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = np.concatenate((np.ones(len(all_positive_tweets)),np.zeros(len(all_negative_tweets))))\n",
    "all_tweets = all_positive_tweets+all_negative_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in all_tweets:\n",
    "    X.append(preprocess_tweets(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_dictionary = build_frequency_dictionary(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = build_features(X,Y,frequency_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.concatenate((data_X[:4000] , data_X[5000:9000])) \n",
    "test_X  = np.concatenate((data_X[4000:5000],data_X[9000:]))\n",
    "train_Y = np.concatenate((np.ones(4000),np.zeros(4000)))\n",
    "test_Y = np.concatenate((np.ones(1000),np.zeros(1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicted = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.992"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_X,test_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
